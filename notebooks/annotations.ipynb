{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6e4bf9d",
   "metadata": {},
   "source": [
    "# Edit Annotations\n",
    "\n",
    "Thanks for using this jupyter notebook. This notebook covers several useful functions to play around with the annotations we have. The list below summarises where you can find codes for each function.\n",
    "\n",
    "### **[Almost always needed]** Importing: \n",
    "Import JSON into DataFrame - Function (1)\n",
    "\n",
    "### Queries and counting:\n",
    "* Count the category (and/or clicks) distribution - Function (2)\n",
    "* Count the extra effort after inference - Function (9)\n",
    "\n",
    "### Visualisation *[in visualisation.ipynb]*\n",
    "* Export detected instances on images - Function (V1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08bc5602-b28f-46ad-82f0-ab422e61669f",
   "metadata": {},
   "source": [
    "# 1) Import JSON into DataFrame\n",
    "\n",
    "Export annotations from CVAT as COCO JSON. \n",
    "\n",
    "Put the json file in the working directory and change the variable \"filename\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317dede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# utilities\n",
    "\n",
    "def findCategory(data):\n",
    "    # find categories\n",
    "    cats = data[\"categories\"]\n",
    "    category = pd.DataFrame(cats)\n",
    "    category = category.drop(['supercategory'], axis=1)\n",
    "    category = category.rename(columns={'id': 'category_id'})\n",
    "    return category\n",
    "\n",
    "def findImages(data):\n",
    "    img = data[\"images\"]\n",
    "    images = pd.DataFrame(img)\n",
    "    \n",
    "    # unwanted columns exist if exported from CVAT. Not if generated by my code\n",
    "    if set(['license','flickr_url','coco_url','date_captured']).issubset(images.columns):\n",
    "        images = images.drop(columns=['license','flickr_url','coco_url','date_captured'])\n",
    "    \n",
    "    return images\n",
    "\n",
    "def findAnnotations(data):\n",
    "    anno = data[\"annotations\"]\n",
    "    df = pd.DataFrame(anno)\n",
    "    return df\n",
    "\n",
    "def cleanForJson(category=None, df=None):\n",
    "    # clean category for json dump\n",
    "    if category is not None:\n",
    "        category = category.rename(columns={'category_id': 'id'})\n",
    "        category['supercategory'] = \"\"\n",
    "\n",
    "    # add columns in df for json dump\n",
    "    if df is not None:\n",
    "        df['iscrowd'] = 0\n",
    "        df['attributes'] = [{'occluded':False}] * len(df['id'])\n",
    "        cols = ['id', 'image_id', 'category_id', 'segmentation', 'area', 'bbox', 'iscrowd', 'attributes']\n",
    "        df = df[cols + [c for c in df.columns if c not in cols]]\n",
    "    \n",
    "    return category, df\n",
    "\n",
    "# convert all np.integer, np.floating and np.ndarray into json recognisable int, float and lists\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a51d1d6-811f-4b2e-8e2e-ef4a736c85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# filename = './A12AL/A12AL_train_11.json'\n",
    "# filename = './input/230725limR101_SS4_p1_2.json'\n",
    "filename = './input/A12_v3.json'\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "    if \"categories\" in data:\n",
    "        category = findCategory(data)\n",
    "    \n",
    "    if \"images\" in data:\n",
    "        images = findImages(data)\n",
    "        nos_image = images['id'].nunique()\n",
    "\n",
    "    df = findAnnotations(data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "487ffaf7-5186-4f98-ae40-7e9ce848b4ad",
   "metadata": {},
   "source": [
    "# 2) Count numbers of defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130a5e1-5032-497f-bf2b-3ab0230f4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "findTotal = False           # Count total number of images\n",
    "area = \"hello\"              # for finding the total number of images\n",
    "qall = True                 # Query all images in df?\n",
    "qclick = False               # Query the number of clicks in segmentation?\n",
    "qarea = False               # Query the area of segmentation masks?\n",
    "\n",
    "# Count total number of images\n",
    "if findTotal == True:\n",
    "    if area == 'A14 Tothill':\n",
    "        nos_image = 2343\n",
    "    elif area == 'A12 Mountnessing':\n",
    "        nos_image = 6580\n",
    "# if not imported from json, manually input nos. images\n",
    "# nos_image = 858\n",
    "        \n",
    "# Count images with defects by querying image id\n",
    "if qall == True:\n",
    "    start_id = 1\n",
    "    end_id = max(df['image_id'])\n",
    "elif qall == False:\n",
    "    start_id = 4356\n",
    "    end_id = 6580\n",
    "\n",
    "df2 = df[(df['image_id']>=start_id) & (df['image_id']<=end_id)]\n",
    "\n",
    "# report the number of instances of defects\n",
    "nos_image_d = df2['image_id'].nunique()\n",
    "nos_defects = len(df2['id'])\n",
    "print(f'{nos_image_d} out of {nos_image} images have defects.\\n{nos_defects} defects in total')\n",
    "\n",
    "# count clicks in segmentations\n",
    "def statsQuick(i, seg_pt, mult=1):\n",
    "    min_num = min(seg_pt)*mult\n",
    "    max_num = max(seg_pt)*mult\n",
    "    q3, q2, q1 = np.percentile(np.array(seg_pt)*mult, [75,50,25])\n",
    "    click_sum = sum(seg_pt)*mult\n",
    "    avg_num = round(click_sum/len(seg_pt),2)\n",
    "    sd = round(np.std(np.array(seg_pt)*mult),2)\n",
    "    return i, avg_num, sd, min_num, q1, q2, q3, max_num\n",
    "\n",
    "if qclick == True:\n",
    "    catidx = np.sort(df2['category_id'].unique()).tolist()\n",
    "    click_count = []\n",
    "    for i in catidx:\n",
    "        df_count = df2[(df2['category_id']==i)]\n",
    "        seg_list = df_count['segmentation'].tolist()\n",
    "        seg_pt = [len(x[0]) if x else 8 for x in seg_list]\n",
    "        click_count.append(statsQuick(i, seg_pt,mult=0.5))\n",
    "\n",
    "# count areas in segmentations\n",
    "if qarea == True:\n",
    "    catidx = np.sort(df2['category_id'].unique()).tolist()\n",
    "    area_count = []\n",
    "    for i in catidx:\n",
    "        df_count = df2[(df2['category_id']==i)]\n",
    "        area_list = df_count['area'].tolist()\n",
    "        area_count.append(statsQuick(i, area_list))\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Create a pivot table that counts the number of instance\n",
    "# -----------------------\n",
    "defect_cat = pd.pivot_table(df2, values='id', index='category_id', aggfunc='count')\n",
    "\n",
    "defect_cat = defect_cat.merge(category[['category_id','name']], left_on='category_id', right_on='category_id')\n",
    "defect_cat = defect_cat.rename(columns={'id': 'counts'})\n",
    "stats_col = [\"category_id\",\"mean\", \"SD\", \"min.\", \"25th percentile\", \"median\", \"75th percentile\",\"max.\"]\n",
    "if qclick == True:\n",
    "    click_cat = pd.DataFrame(np.array(click_count), columns=stats_col)\n",
    "    defect_cat = defect_cat.merge(click_cat, left_on='category_id', right_on='category_id')\n",
    "if qarea == True:\n",
    "    area_cat = pd.DataFrame(np.array(area_count), columns=stats_col)\n",
    "    defect_cat = defect_cat.merge(area_cat, left_on='category_id', right_on='category_id')\n",
    "\n",
    "defect_cat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00e5a9a2",
   "metadata": {},
   "source": [
    "# 9) Count extra effort after inference\n",
    "\n",
    "I use two metrics to evaluate the annotation process. One is the quality of annotations, which is evaluated by some measures of precisions and recalls.\n",
    "\n",
    "The other is human effort measured by the number of clicks.\n",
    "\n",
    "Concretely, after receiving the inference annotation file and GT file, I will need to measure:\n",
    "* how many masks are deleted (1 click per box)\n",
    "* how many categories are changed (2 clicks per box)\n",
    "* how many masks are added\n",
    "    * treat as no change if bbox hasn't moved (just being picky to refine the masks)\n",
    "    * for genuinely new masks, use the median number of clicks for the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4502e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to format dataFrames\n",
    "def extractLists(df):\n",
    "    gt_bboxes = df['bbox'].to_list()\n",
    "    gt_catids = df['category_id'].to_list()\n",
    "    return gt_bboxes, gt_catids\n",
    "\n",
    "def _imgReindex(df, images_new):\n",
    "    for i in range(len(df['id'])):\n",
    "        df.loc[i, 'image_id'] = images_new.loc[(images_new['file_name']==df['file_name'][i]), 'id'].values\n",
    "    df = df.sort_values(by=['image_id'], ignore_index=True)\n",
    "    df['id'] = df.index + 1\n",
    "    df = df.drop(columns=['file_name'])\n",
    "    return df\n",
    "\n",
    "def imageReindex(df, df2, images, images2):\n",
    "    # Merge two annotation df\n",
    "    df_new = pd.concat([df, df2], ignore_index = True)\n",
    "\n",
    "    # Combine and re-arrange the image info\n",
    "    images_new = pd.DataFrame(columns=['id','width','height','file_name'])\n",
    "    images_new['file_name'] = df_new['file_name'].unique()\n",
    "    images_new = images_new.sort_values(by=['file_name'], ignore_index=True)\n",
    "    images_new['id'] = images_new.index + 1\n",
    "    # Fill in width and height parameters of each image\n",
    "    for i in range(len(images_new['file_name'])):\n",
    "        # find out which json records the concerned image\n",
    "        if images_new['file_name'][i] in images['file_name'].tolist():\n",
    "            dim = images.loc[(images['file_name']==images_new['file_name'][i]),['width','height']]\n",
    "        elif images_new['file_name'][i] in images2['file_name'].tolist():\n",
    "            dim = images2.loc[(images2['file_name']==images_new['file_name'][i]),['width','height']]\n",
    "        else:\n",
    "            print('image not included')\n",
    "            continue\n",
    "        # paste width and height info\n",
    "        images_new.loc[i,'width'] = dim['width'].values[0]\n",
    "        images_new.loc[i,'height'] = dim['height'].values[0]\n",
    "\n",
    "    # Assign new image id and defect id in df and df2\n",
    "    df = _imgReindex(df, images_new)\n",
    "    df2 = _imgReindex(df2, images_new)\n",
    "\n",
    "    return df, df2, images_new\n",
    "\n",
    "\n",
    "# Functions to check bbox movements/additions/deletions\n",
    "def compare_bboxes(image_id, pseudolabels, ground_truths, ps_cat, gt_cat, centroid_threshold=10, areadiff_threshold=0.1):\n",
    "    deleted_bboxes = []\n",
    "    added_bboxes = []\n",
    "    changed_size_bboxes = []\n",
    "    same_bboxes = []\n",
    "\n",
    "    pseudolabel_matched = [False] * len(pseudolabels)\n",
    "    ground_truth_matched = [False] * len(ground_truths)\n",
    "\n",
    "    # Check for deleted and changed size bounding boxes\n",
    "    for idx, p_bbox in enumerate(pseudolabels):\n",
    "        found_match = False\n",
    "        for gt_idx, gt_bbox in enumerate(ground_truths):\n",
    "            \n",
    "            # find area difference\n",
    "            p_area = (p_bbox[2] - p_bbox[0]) * (p_bbox[3] - p_bbox[1])\n",
    "            gt_area = (gt_bbox[2] - gt_bbox[0]) * (gt_bbox[3] - gt_bbox[1])\n",
    "            try:\n",
    "                area_diff = abs(p_area - gt_area) / max(p_area, gt_area)\n",
    "            except:\n",
    "                # print(f'image {image_id} pseudolabel {idx} p_area = {p_area}, GT label {gt_idx} gt_area = {gt_area}')\n",
    "                continue\n",
    "\n",
    "            # find centroid distance\n",
    "            p_centroid = ((p_bbox[0] + p_bbox[2]) / 2, (p_bbox[1] + p_bbox[3]) / 2)\n",
    "            gt_centroid = ((gt_bbox[0] + gt_bbox[2]) / 2, (gt_bbox[1] + gt_bbox[3]) / 2)\n",
    "            centroid_dist = ((p_centroid[0] - gt_centroid[0]) ** 2 + (p_centroid[1] - gt_centroid[1]) ** 2) ** 0.5\n",
    "\n",
    "            # print(f'Psuedolabel {idx} vs GT label {gt_idx}, area diff = {area_diff}, centroid dist = {centroid_dist}')\n",
    "            if area_diff <= areadiff_threshold and centroid_dist <= centroid_threshold:\n",
    "                found_match = True\n",
    "                ground_truth_matched[gt_idx] = True\n",
    "                if area_diff <= 0.1 and centroid_dist <= centroid_threshold * 0.1:\n",
    "                    same_bboxes.append((idx, p_bbox, image_id, ps_cat[idx]))\n",
    "                else:\n",
    "                    changed_size_bboxes.append((idx, p_bbox, image_id, ps_cat[idx]))\n",
    "                break\n",
    "            \n",
    "            # iou_value = iou(p_bbox, gt_bbox)\n",
    "            # if iou_value >= iou_threshold:\n",
    "            #     found_match = True\n",
    "            #     ground_truth_matched[gt_idx] = True\n",
    "\n",
    "            #     if abs(p_bbox[0] - gt_bbox[0]) > threshold or \\\n",
    "            #             abs(p_bbox[1] - gt_bbox[1]) > threshold or \\\n",
    "            #             abs(p_bbox[2] - gt_bbox[2]) > threshold or \\\n",
    "            #             abs(p_bbox[3] - gt_bbox[3]) > threshold:\n",
    "            #         changed_size_bboxes.append((idx, p_bbox, image_id, ps_cat[idx]))\n",
    "            #     break\n",
    "\n",
    "        if not found_match:\n",
    "            deleted_bboxes.append((idx, p_bbox, image_id, ps_cat[idx]))\n",
    "\n",
    "    # Check for added bounding boxes\n",
    "    for idx, gt_bbox in enumerate(ground_truths):\n",
    "        if not ground_truth_matched[idx]:\n",
    "            added_bboxes.append((idx, gt_bbox, image_id, gt_cat[idx]))\n",
    "\n",
    "    return deleted_bboxes, added_bboxes, changed_size_bboxes, same_bboxes\n",
    "\n",
    "def compare_cats(image_id, pseudolabels, ground_truths, ps_cat, gt_cat, iou_threshold=0.5):\n",
    "    changed_cats_bboxes = []\n",
    "    ground_truth_matched = [False] * len(ground_truths)\n",
    "    \n",
    "    # Check for deleted and changed size bounding boxes\n",
    "    for idx, p_bbox in enumerate(pseudolabels):\n",
    "        for gt_idx, gt_bbox in enumerate(ground_truths):\n",
    "            iou_value = iou(p_bbox, gt_bbox)\n",
    "            if iou_value >= iou_threshold:\n",
    "                ground_truth_matched[gt_idx] = True\n",
    "                if gt_cat[gt_idx] != ps_cat[idx]:       # changed GT categories\n",
    "                    changed_cats_bboxes.append((idx, p_bbox, image_id, gt_cat[gt_idx]))\n",
    "    \n",
    "    return changed_cats_bboxes\n",
    "\n",
    "def iou(bbox1, bbox2):\n",
    "    # Calculate the Intersection over Union (IoU) of two bounding boxes\n",
    "    x1 = max(bbox1[0], bbox2[0])\n",
    "    y1 = max(bbox1[1], bbox2[1])\n",
    "    x2 = min(bbox1[2], bbox2[2])\n",
    "    y2 = min(bbox1[3], bbox2[3])\n",
    "\n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area_bbox1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])\n",
    "    area_bbox2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])\n",
    "\n",
    "    if area_bbox1>0 or area_bbox2>0:\n",
    "        iou_value = intersection / (area_bbox1 + area_bbox2 - intersection)\n",
    "    else:\n",
    "        iou_value = 0\n",
    "    \n",
    "    return iou_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a0f3a",
   "metadata": {},
   "source": [
    "### Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97641a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Files to be compared\n",
    "# gt_file = './input/SS4_GT.json'\n",
    "# ps_file = './input/230810_SS4_coninferred_c3_3.json'\n",
    "gt_file = '../data/A12AL/A12AL_val4_SS4.json'\n",
    "ps_file = '../output/240218_al/labels/inferred_14.json'\n",
    "# click_stat = {1: 8.5, 2: 6, 3: 5, 4: 5, 5: 8, 6: 7, 7: 6.5, 10: 6, 11: 7, 12: 5}\n",
    "click_stat = {1: 5, 2: 5, 3: 6, 4: 7, 5: 5}\n",
    "del_click = 1\n",
    "chsize_click = 4\n",
    "chcat_click = 2\n",
    "centroid_tolerance = 0.2\n",
    "areadiff_deladd = 0.4\n",
    "# iou_deladd = 0.1\n",
    "iou_chcat = 0.1\n",
    "\n",
    "# Store categories, images and annotations in separate dataframes\n",
    "with open(gt_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    category = findCategory(data)\n",
    "    images = findImages(data)\n",
    "    nos_image = images['id'].max()\n",
    "    df = findAnnotations(data)\n",
    "    df = df.merge(images[['id','file_name']], left_on='image_id', right_on='id').rename(columns={'id_x': 'id'}).drop(columns=['id_y'])\n",
    "\n",
    "with open(ps_file, 'r') as file:\n",
    "    data2 = json.load(file)\n",
    "    category2 = findCategory(data2)\n",
    "    images2 = findImages(data2)\n",
    "    nos_image2 = images2['id'].max()\n",
    "    df2 = findAnnotations(data2)\n",
    "    df2 = df2.merge(images2[['id','file_name']], left_on='image_id', right_on='id').rename(columns={'id_x': 'id'}).drop(columns=['id_y'])\n",
    "\n",
    "# -------------------------------------\n",
    "# Safety checks\n",
    "# -------------------------------------\n",
    "# Check if categories are the same\n",
    "# check length\n",
    "if len(category) != len(category2):\n",
    "    print('categories not the same. Check before proceeding')\n",
    "# check each category\n",
    "for i in range(len(category['name'])):\n",
    "    if category['name'][i] != category2['name'][i]:\n",
    "        print('category id: {} , {} in file 1 different from category id: {} , {} in file 2. Please check'.format(category['category_id'][i], category['name'][i], category2['category_id'][i], category2['name'][i]))\n",
    "# clean category for json dump\n",
    "category, df = cleanForJson(category, df)\n",
    "category2, df2 = cleanForJson(category2, df2)\n",
    "\n",
    "# Update image_id\n",
    "df, df2, images_new = imageReindex(df, df2, images, images2)\n",
    "img_id_list = images_new['id'].to_list()\n",
    "\n",
    "# ---------------------------------------\n",
    "# Compare Annotations\n",
    "# ---------------------------------------\n",
    "effort_accum = []\n",
    "\n",
    "for image_id in img_id_list:\n",
    "    # Extract inferred bboxes and GT bboxes\n",
    "    gt_df = df[(df['image_id']==image_id)]\n",
    "    ps_df = df2[(df2['image_id']==image_id)]\n",
    "    gt_bboxes, gt_catids = extractLists(gt_df)\n",
    "    pred_bboxes, pred_catids = extractLists(ps_df)\n",
    "\n",
    "    # Extract image dimensions\n",
    "    dim = images_new.loc[(images_new['id']==image_id), ['width', 'height']].values\n",
    "    image_width = int(dim[0][0])\n",
    "    image_height = int(dim[0][1])\n",
    "    centroid_threshold = max(image_width, image_height) * centroid_tolerance\n",
    "\n",
    "    # Compare bboxes\n",
    "    # deleted, added, changed_size = compare_bboxes(image_id, pred_bboxes, gt_bboxes, pred_catids, gt_catids, iou_threshold=iou_deladd)\n",
    "    deleted, added, changed_size, same = compare_bboxes(image_id, pred_bboxes, gt_bboxes, pred_catids, gt_catids, centroid_threshold, areadiff_deladd)\n",
    "    changed_cats = compare_cats(image_id, pred_bboxes, gt_bboxes, pred_catids, gt_catids, iou_threshold=iou_chcat)\n",
    "\n",
    "    # Calculate efforts for additions\n",
    "    add_cat = [x[3] for x in added]\n",
    "    add_click = [click_stat[x] for x in add_cat]\n",
    "    effort_accum.append([image_id, len(deleted), len(added), len(changed_size), len(same), len(changed_cats), add_cat, sum(add_click)])\n",
    "\n",
    "human_effort = pd.DataFrame(effort_accum, columns=['image_id','deleted','added', 'chsize', 'same', 'chcat', 'added_cat', 'clicks_add'])\n",
    "\n",
    "# ----------------------------------------\n",
    "# Calculate the number of clicks needed\n",
    "# ----------------------------------------\n",
    "human_effort['clicks_del'] = human_effort['deleted'] * del_click\n",
    "human_effort['clicks_chsize'] = human_effort['chsize'] * chsize_click\n",
    "human_effort['clicks_chcat'] = human_effort['chcat'] * chcat_click\n",
    "human_effort['subtotal'] = human_effort['clicks_del'] + human_effort['clicks_add'] + human_effort['clicks_chsize'] + human_effort['clicks_chcat']\n",
    "\n",
    "print(\"File:\", ps_file)\n",
    "print(\"Total clicks:\",sum(human_effort['subtotal']),'\\n'\n",
    "      \"Added:\",sum(human_effort['added']),'\\n'\n",
    "      \"Deleted:\",sum(human_effort['deleted']),'\\n'\n",
    "      \"Changed Size:\", sum(human_effort['chsize']),'\\n'\n",
    "      \"Same\", sum(human_effort['same']),'\\n'\n",
    "      \"Changed Category:\",sum(human_effort['chcat'])\n",
    ")\n",
    "\n",
    "# human_effort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535c3a9",
   "metadata": {},
   "source": [
    "### Multiple annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0270a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json, os\n",
    "\n",
    "# Files to be compared\n",
    "# gt_file = './input/SS4_GT.json'\n",
    "# ps_file = './input/230810_SS4_coninferred_c3_3.json'\n",
    "gt_file = '../data/A12AL/A12AL_val4_SS4.json'\n",
    "ps_dir = \"../output/240218_al/labels\"\n",
    "ps_header = \"Corr\"     # no need to include the underscore\n",
    "eval_dir = \"/mnt/c/Users/phl25/Downloads/transit/240202_casac\"\n",
    "\n",
    "# click_stat = {1: 8.5, 2: 6, 3: 5, 4: 5, 5: 8, 6: 7, 7: 6.5, 10: 6, 11: 7, 12: 5}\n",
    "click_stat = {1: 5, 2: 5, 3: 6, 4: 7, 5: 5}\n",
    "del_click = 1\n",
    "chsize_click = 4\n",
    "chcat_click = 2\n",
    "centroid_tolerance = 0.2\n",
    "areadiff_deladd = 0.4\n",
    "# iou_deladd = 0.1\n",
    "iou_chcat = 0.1\n",
    "result_accum = []\n",
    "\n",
    "for it in range(0,28):\n",
    "    ps_file = os.path.join(ps_dir,f'{ps_header}_{str(it).zfill(2)}.json')\n",
    "\n",
    "    # Store categories, images and annotations in separate dataframes\n",
    "    with open(gt_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        category = findCategory(data)\n",
    "        images = findImages(data)\n",
    "        nos_image = images['id'].max()\n",
    "        df = findAnnotations(data)\n",
    "        df = df.merge(images[['id','file_name']], left_on='image_id', right_on='id').rename(columns={'id_x': 'id'}).drop(columns=['id_y'])\n",
    "\n",
    "    with open(ps_file, 'r') as file:\n",
    "        data2 = json.load(file)\n",
    "        category2 = findCategory(data2)\n",
    "        images2 = findImages(data2)\n",
    "        nos_image2 = images2['id'].max()\n",
    "        df2 = findAnnotations(data2)\n",
    "        df2 = df2.merge(images2[['id','file_name']], left_on='image_id', right_on='id').rename(columns={'id_x': 'id'}).drop(columns=['id_y'])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Safety checks\n",
    "    # -------------------------------------\n",
    "    # Check if categories are the same\n",
    "    # check length\n",
    "    if len(category) != len(category2):\n",
    "        print('categories not the same. Check before proceeding')\n",
    "    # check each category\n",
    "    for i in range(len(category['name'])):\n",
    "        if category['name'][i] != category2['name'][i]:\n",
    "            print('category id: {} , {} in file 1 different from category id: {} , {} in file 2. Please check'.format(category['category_id'][i], category['name'][i], category2['category_id'][i], category2['name'][i]))\n",
    "    # clean category for json dump\n",
    "    category, df = cleanForJson(category, df)\n",
    "    category2, df2 = cleanForJson(category2, df2)\n",
    "\n",
    "    # Update image_id\n",
    "    df, df2, images_new = imageReindex(df, df2, images, images2)\n",
    "    img_id_list = images_new['id'].to_list()\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Compare Annotations\n",
    "    # ---------------------------------------\n",
    "    effort_accum = []\n",
    "\n",
    "    for image_id in img_id_list:\n",
    "        # Extract inferred bboxes and GT bboxes\n",
    "        gt_df = df[(df['image_id']==image_id)]\n",
    "        ps_df = df2[(df2['image_id']==image_id)]\n",
    "        gt_bboxes, gt_catids = extractLists(gt_df)\n",
    "        pred_bboxes, pred_catids = extractLists(ps_df)\n",
    "\n",
    "        # Extract image dimensions\n",
    "        dim = images_new.loc[(images_new['id']==image_id), ['width', 'height']].values\n",
    "        image_width = int(dim[0][0])\n",
    "        image_height = int(dim[0][1])\n",
    "        centroid_threshold = max(image_width, image_height) * centroid_tolerance\n",
    "\n",
    "        # Compare bboxes\n",
    "        # deleted, added, changed_size = compare_bboxes(image_id, pred_bboxes, gt_bboxes, pred_catids, gt_catids, iou_threshold=iou_deladd)\n",
    "        deleted, added, changed_size, same = compare_bboxes(image_id, pred_bboxes, gt_bboxes, pred_catids, gt_catids, centroid_threshold, areadiff_deladd)\n",
    "        changed_cats = compare_cats(image_id, pred_bboxes, gt_bboxes, pred_catids, gt_catids, iou_threshold=iou_chcat)\n",
    "\n",
    "        # Calculate efforts for additions\n",
    "        add_cat = [x[3] for x in added]\n",
    "        add_click = [click_stat[x] for x in add_cat]\n",
    "        effort_accum.append([image_id, len(deleted), len(added), len(changed_size), len(same), len(changed_cats), add_cat, sum(add_click)])\n",
    "\n",
    "    human_effort = pd.DataFrame(effort_accum, columns=['image_id','deleted','added', 'chsize', 'same', 'chcat', 'added_cat', 'clicks_add'])\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Calculate the number of clicks needed\n",
    "    # ----------------------------------------\n",
    "    human_effort['clicks_del'] = human_effort['deleted'] * del_click\n",
    "    human_effort['clicks_chsize'] = human_effort['chsize'] * chsize_click\n",
    "    human_effort['clicks_chcat'] = human_effort['chcat'] * chcat_click\n",
    "    human_effort['subtotal'] = human_effort['clicks_del'] + human_effort['clicks_add'] + human_effort['clicks_chsize'] + human_effort['clicks_chcat']\n",
    "    result_accum.append([os.path.basename(ps_file), sum(human_effort['subtotal']), sum(human_effort['added']), sum(human_effort['deleted']), sum(human_effort['chsize']), sum(human_effort['same']), sum(human_effort['chcat'])])\n",
    "    \n",
    "result_df = pd.DataFrame(result_accum, columns=['file','total_clicks','added','deleted','changed_size','same','changed_cat'])\n",
    "file_name = f'{ps_header}_clicks.xlsx'\n",
    "result_df.to_excel(os.path.join(eval_dir, file_name),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
