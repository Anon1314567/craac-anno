{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended functions on annotations\n",
    "\n",
    "This jupyter notebook is written to allow extra visualisation capabilities on the created annotations, aside from format conversions and counting as provided in *annotations.ipynb*. \n",
    "\n",
    "Functions here will be expanded as the project progresses.\n",
    "\n",
    "### Visualisation\n",
    "* V1 - visualise detected instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities for creating dataFrames from annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, json, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from pycocotools import mask as cocomask\n",
    "\n",
    "# utilities\n",
    "\n",
    "def findCategory(data):\n",
    "    # find categories\n",
    "    cats = data[\"categories\"]\n",
    "    category = pd.DataFrame(cats)\n",
    "    category = category.drop(['supercategory'], axis=1)\n",
    "    category = category.rename(columns={'id': 'category_id'})\n",
    "    return category\n",
    "\n",
    "def findImages(data):\n",
    "    img = data[\"images\"]\n",
    "    images = pd.DataFrame(img)\n",
    "    \n",
    "    # unwanted columns exist if exported from CVAT. Not if generated by my code\n",
    "    if set(['license','flickr_url','coco_url','date_captured']).issubset(images.columns):\n",
    "        images = images.drop(columns=['license','flickr_url','coco_url','date_captured'])\n",
    "    \n",
    "    return images\n",
    "\n",
    "def findAnnotations(data):\n",
    "    anno = data[\"annotations\"]\n",
    "    df = pd.DataFrame(anno)\n",
    "    return df\n",
    "\n",
    "def cleanForJson(category=None, df=None):\n",
    "    # clean category for json dump\n",
    "    if category is not None:\n",
    "        category = category.rename(columns={'category_id': 'id'})\n",
    "        category['supercategory'] = \"\"\n",
    "\n",
    "    # add columns in df for json dump\n",
    "    if df is not None:\n",
    "        df['iscrowd'] = 0\n",
    "        df['attributes'] = [{'occluded':False}] * len(df['id'])\n",
    "        cols = ['id', 'image_id', 'category_id', 'segmentation', 'area', 'bbox', 'iscrowd', 'attributes']\n",
    "        df = df[cols + [c for c in df.columns if c not in cols]]\n",
    "    \n",
    "    return category, df\n",
    "\n",
    "# convert all np.integer, np.floating and np.ndarray into json recognisable int, float and lists\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def drop_columns_if_exist(df, columns):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=col)\n",
    "    return df\n",
    "\n",
    "def createDF(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        category = findCategory(data)\n",
    "        images = findImages(data)\n",
    "        # nos_image = images['id'].max()\n",
    "        df = findAnnotations(data)\n",
    "        df = df.merge(images[['id','file_name']], left_on='image_id', right_on='id')\n",
    "        df = df.rename(columns={'id_x': 'id'})\n",
    "        df = drop_columns_if_exist(df,columns=['iscrowd','attributes','id_y'])\n",
    "        return category, images, df\n",
    "\n",
    "def fix_image_id(image1, image2, df, df2):\n",
    "    \n",
    "    image_comb = pd.concat([image1, image2], ignore_index = True)                              # combine image 1 and 2\n",
    "    # sort and find unique image names\n",
    "    image_comb = image_comb.sort_values(by=['file_name']).reset_index(drop=True)               # sort by image name\n",
    "    image_new = image_comb.drop_duplicates(subset=['file_name'])                               # Get unique image names\n",
    "    image_new = image_new.reset_index(drop=True)                                               # reset index\n",
    "    image_new['id'] = image_new.index + 1                                                      # create new image id\n",
    "\n",
    "    image1 = image1.merge(image_new[['id', 'file_name']], on='file_name', how='left')        # map image_id to image1 and image2\n",
    "    image2 = image2.merge(image_new[['id', 'file_name']], on='file_name', how='left')        # map image_id to image1 and image2\n",
    "\n",
    "    # use new id in image to replace old image_id in df\n",
    "    df = df.merge(image1[['id_x', 'id_y']], left_on='image_id', right_on='id_x', how='left')\n",
    "    df2 = df2.merge(image2[['id_x', 'id_y']], left_on='image_id', right_on='id_x', how='left')\n",
    "    df = df.drop(columns=['image_id', 'id_x']).rename(columns={'id_y': 'image_id'})\n",
    "    df2 = df2.drop(columns=['image_id', 'id_x']).rename(columns={'id_y': 'image_id'})\n",
    "\n",
    "    # Make good the dfs\n",
    "    df['iscrowd'] = 0\n",
    "    df['attributes'] = [{'occluded':False}] * len(df['id'])\n",
    "    df = df.drop(columns=['file_name'])\n",
    "    df2['iscrowd'] = 0\n",
    "    df2['attributes'] = [{'occluded':False}] * len(df2['id'])\n",
    "    df2 = df2.drop(columns=['file_name'])\n",
    "\n",
    "    return image_new, df, df2\n",
    "\n",
    "def polygon_to_mask(polygons, height, width):\n",
    "    '''\n",
    "    Args:\n",
    "        polygon (list): in [[...]]\n",
    "        height, width (int): height and width of image\n",
    "    Returns:\n",
    "        np.array: a mask of shape (H, W)\n",
    "    '''\n",
    "    the_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # tackle the problem of having >1 polygon in an instance\n",
    "    if len(polygons) > 1:\n",
    "        for poly in polygons:\n",
    "            # poly = np.array(poly).reshape((-1, 2))\n",
    "            rles = cocomask.frPyObjects([poly], height, width)\n",
    "            a_mask = np.squeeze(cocomask.decode(rles))\n",
    "            # print(a_mask.shape)\n",
    "            the_mask = np.logical_or(the_mask, a_mask)\n",
    "    else:\n",
    "        rles = cocomask.frPyObjects(polygons, height, width)\n",
    "        the_mask = np.squeeze(cocomask.decode(rles))\n",
    "\n",
    "    return the_mask\n",
    "\n",
    "def bbox_convert(bbox):\n",
    "    x1, y1, w, h = bbox\n",
    "    bbox_new = [x1, y1, x1+w, y1+h]\n",
    "    return bbox_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1. Visualise detected instances on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.structures import Boxes, Instances\n",
    "import torch\n",
    "\n",
    "gt_file = \"../data/A12AL/A12AL_val4_SS4.json\"\n",
    "vis_dir = '../images/vis_gt/'\n",
    "register_coco_instances(\"4vis\", {}, gt_file, \"../images/train_all\")\n",
    "\n",
    "category, images, df = createDF(gt_file)\n",
    "\n",
    "dataset_vis = DatasetCatalog.get('4vis')\n",
    "dataset_vis_metadata = MetadataCatalog.get('4vis')\n",
    "\n",
    "for d in dataset_vis:\n",
    "    d_name = os.path.basename(d[\"file_name\"])\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    height, width = img.shape[:2]\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=dataset_vis_metadata, scale=1)\n",
    "    df_related = df[df['file_name'] == d_name]\n",
    "\n",
    "    # draw_instance_predictions requires an Instances object in torch\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if len(df_related) != 0:\n",
    "        temp_instances = Instances((height,width)).to(device)\n",
    "        pred_boxes = [torch.tensor(bbox_convert(row['bbox']), dtype=torch.float32) for index, row in df_related.iterrows()] # present bbox as [x1, y1, x2, y2] and convert to tensor\n",
    "        temp_instances.pred_boxes = Boxes(torch.stack(pred_boxes))\n",
    "        if 'score' in df.columns:                           \n",
    "            temp_instances.scores = torch.tensor([row['score'] for index, row in df_related.iterrows()])\n",
    "        temp_instances.pred_classes = torch.tensor([row['category_id'] - 1 for index, row in df_related.iterrows()])        # metedata starts from 0\n",
    "        pred_masks = [torch.tensor(polygon_to_mask(row['segmentation'], height, width)) for index, row in df_related.iterrows()]\n",
    "        temp_instances.pred_masks = torch.stack(pred_masks)\n",
    "        out = visualizer.draw_instance_predictions(temp_instances)\n",
    "    else:                                                                       # if no instances, draw gt\n",
    "        out = visualizer.draw_dataset_dict(d)\n",
    "\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    (filepath, filename) = os.path.split(d['file_name'])\n",
    "    save_name = os.path.join(vis_dir,filename)\n",
    "    cv2.imwrite(save_name, out.get_image()[:, :, ::-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear previous registry\n",
    "\n",
    "dataset_to_clear = ['4vis']\n",
    "\n",
    "for i in dataset_to_clear:\n",
    "    DatasetCatalog.remove(i)\n",
    "    MetadataCatalog.remove(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
